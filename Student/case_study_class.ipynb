{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "695ef483-e2e7-40a4-8b01-5912730f963d",
   "metadata": {},
   "source": [
    "# Lesson 3.8: Multi-class classification & Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94022d19",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Lesson-3.8:-Multi-class-classification-&amp;-Classification-models\" data-toc-modified-id=\"Lesson-3.8:-Multi-class-classification-&amp;-Classification-models-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Lesson 3.8: Multi-class classification &amp; Classification models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Lesson-description\" data-toc-modified-id=\"Lesson-description-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Lesson description</a></span></li><li><span><a href=\"#Classification\" data-toc-modified-id=\"Classification-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Classification</a></span><ul class=\"toc-item\"><li><span><a href=\"#Multi-class-classification\" data-toc-modified-id=\"Multi-class-classification-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Multi-class classification</a></span><ul class=\"toc-item\"><li><span><a href=\"#One-vs-Rest-(OvR)\" data-toc-modified-id=\"One-vs-Rest-(OvR)-1.2.1.1\"><span class=\"toc-item-num\">1.2.1.1&nbsp;&nbsp;</span>One-vs-Rest (OvR)</a></span></li><li><span><a href=\"#One-vs-One-(OvO)\" data-toc-modified-id=\"One-vs-One-(OvO)-1.2.1.2\"><span class=\"toc-item-num\">1.2.1.2&nbsp;&nbsp;</span>One-vs-One (OvO)</a></span></li></ul></li></ul></li><li><span><a href=\"#Data-analysis-workflow\" data-toc-modified-id=\"Data-analysis-workflow-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Data analysis workflow</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Understanding-&amp;-Data-Preparation\" data-toc-modified-id=\"Data-Understanding-&amp;-Data-Preparation-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Data Understanding &amp; Data Preparation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-libraries\" data-toc-modified-id=\"Import-libraries-1.3.1.1\"><span class=\"toc-item-num\">1.3.1.1&nbsp;&nbsp;</span>Import libraries</a></span></li><li><span><a href=\"#Load-the-data\" data-toc-modified-id=\"Load-the-data-1.3.1.2\"><span class=\"toc-item-num\">1.3.1.2&nbsp;&nbsp;</span>Load the data</a></span></li><li><span><a href=\"#Data-understanding\" data-toc-modified-id=\"Data-understanding-1.3.1.3\"><span class=\"toc-item-num\">1.3.1.3&nbsp;&nbsp;</span>Data understanding</a></span></li><li><span><a href=\"#Data-cleaning\" data-toc-modified-id=\"Data-cleaning-1.3.1.4\"><span class=\"toc-item-num\">1.3.1.4&nbsp;&nbsp;</span>Data cleaning</a></span></li></ul></li><li><span><a href=\"#Data-pre-processing\" data-toc-modified-id=\"Data-pre-processing-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Data pre-processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-train-and-test\" data-toc-modified-id=\"Create-train-and-test-1.3.2.1\"><span class=\"toc-item-num\">1.3.2.1&nbsp;&nbsp;</span>Create train and test</a></span></li><li><span><a href=\"#Feature-engineering\" data-toc-modified-id=\"Feature-engineering-1.3.2.2\"><span class=\"toc-item-num\">1.3.2.2&nbsp;&nbsp;</span>Feature engineering</a></span></li></ul></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-regression\" data-toc-modified-id=\"Logistic-regression-1.3.3.1\"><span class=\"toc-item-num\">1.3.3.1&nbsp;&nbsp;</span>Logistic regression</a></span></li><li><span><a href=\"#Prediction\" data-toc-modified-id=\"Prediction-1.3.3.2\"><span class=\"toc-item-num\">1.3.3.2&nbsp;&nbsp;</span>Prediction</a></span></li><li><span><a href=\"#Probabilities\" data-toc-modified-id=\"Probabilities-1.3.3.3\"><span class=\"toc-item-num\">1.3.3.3&nbsp;&nbsp;</span>Probabilities</a></span></li></ul></li><li><span><a href=\"#Evaluating-the-model\" data-toc-modified-id=\"Evaluating-the-model-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>Evaluating the model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Confusion-Matrix\" data-toc-modified-id=\"Confusion-Matrix-1.3.4.1\"><span class=\"toc-item-num\">1.3.4.1&nbsp;&nbsp;</span>Confusion Matrix</a></span></li><li><span><a href=\"#Classification-Report\" data-toc-modified-id=\"Classification-Report-1.3.4.2\"><span class=\"toc-item-num\">1.3.4.2&nbsp;&nbsp;</span>Classification Report</a></span></li></ul></li></ul></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Summary</a></span></li><li><span><a href=\"#Additional-resources\" data-toc-modified-id=\"Additional-resources-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Additional resources</a></span></li><li><span><a href=\"#Exercise-1\" data-toc-modified-id=\"Exercise-1-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Exercise 1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Answer\" data-toc-modified-id=\"Answer-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span>Answer</a></span></li></ul></li><li><span><a href=\"#Exercise-2\" data-toc-modified-id=\"Exercise-2-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Exercise 2</a></span><ul class=\"toc-item\"><li><span><a href=\"#Answer\" data-toc-modified-id=\"Answer-1.7.1\"><span class=\"toc-item-num\">1.7.1&nbsp;&nbsp;</span>Answer</a></span></li></ul></li><li><span><a href=\"#Exercise-3\" data-toc-modified-id=\"Exercise-3-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Exercise 3</a></span><ul class=\"toc-item\"><li><span><a href=\"#Answer\" data-toc-modified-id=\"Answer-1.8.1\"><span class=\"toc-item-num\">1.8.1&nbsp;&nbsp;</span>Answer</a></span></li></ul></li><li><span><a href=\"#Exercise-4\" data-toc-modified-id=\"Exercise-4-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Exercise 4</a></span><ul class=\"toc-item\"><li><span><a href=\"#Answer\" data-toc-modified-id=\"Answer-1.9.1\"><span class=\"toc-item-num\">1.9.1&nbsp;&nbsp;</span>Answer</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95326320-477e-456a-8af0-c525a4cd6010",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Lesson description\n",
    "\n",
    "**Lesson Purpose**: the purpose of this lesson is to introduce **multi-class classification** problems and revisit the **data analysis workflow** with classification modeling using **logistic regression**.\n",
    "\n",
    "**Learning Objectives**\n",
    "\n",
    "After this lesson, students will be able to:\n",
    "\n",
    "- Conceptualize the data analysis workflow\n",
    "- Explain logistic regression\n",
    "- Differentiate binary classification and multi-class classification problems\n",
    "- Use logistic regression for multi class classification\n",
    "- Check the accuracy of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb23343c-f980-4d5c-b5fc-730a7030a363",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd941ab4-9bed-4573-a8ee-88409a97cd92",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Remember**: **Classification** models are used when the target variable is **qualitative**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c7c278-6cf2-476b-9a73-3f9b5f676df5",
   "metadata": {},
   "source": [
    "**Types of Classification:**\n",
    "- **Binary Classification**: Classification tasks with **two classes**. Example: paying back (or not) a loan, checking email is spam or not.\n",
    "- **Multi-class Classification**: Classification tasks with **more than two classes**. Example: classification of news in different categories.\n",
    "\n",
    "\n",
    "A classification problem can be both, binary and multi-class, depending on how we formulate the business problem. Example: sentiment analysis. If the classes are just ‚Äúpositive‚Äù and ‚Äúnegative‚Äù, then it will be a problem of binary class. But if the classes are ‚Äúsadness‚Äù, happiness‚Äù, ‚Äúdisgusting‚Äù, ‚Äúdepressed‚Äù, then it will be a problem of Multi-class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7af6012-a877-4f52-9ac0-0592986bd763",
   "metadata": {},
   "source": [
    "![image.png](img/binary_vs_multiclass.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306ce2a0-d41f-4f5a-b0ba-06f4d965b3cc",
   "metadata": {},
   "source": [
    "### Multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f270faa1-5775-4408-b811-06da635b07bd",
   "metadata": {},
   "source": [
    "Some algorithms are designed for binary classification problems. For example: logistic regression. As such, they **cannot be used for multi-class classification tasks directly**.\n",
    "\n",
    "How do we use them for multi-class classification?\n",
    "\n",
    "- There are methods that can be used to split a **multi-class classification problem into multiple binary classification problems**: OvR, OvO.\n",
    "- We can use an **adapted version of the algorithm**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fa4c23-9b05-4420-90fe-53b5e8ce1e0c",
   "metadata": {},
   "source": [
    "#### One-vs-Rest (OvR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be441d1-0e32-4e4f-937c-4c8ec7cfb7cf",
   "metadata": {},
   "source": [
    "\n",
    "Our model will **compare one class against all other classes**, and perform this step for all classes. This way, we transform the multi-class problem into a **multi-binary problem**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32ae68a-151d-415e-abb0-6c83dc157929",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"img/one-vs-all.png\" width=\"1000\">\n",
    "\n",
    "We will have as many binary models and datasets as number of classes. So we would create 3 binary models (for that we need 3 new datasets as we can see from the image), and we choose the highest probability from those 3 models as the predicted class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f8e79-4950-4bfa-bc85-78d34df03b56",
   "metadata": {},
   "source": [
    "#### One-vs-One (OvO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9218d913-ed51-4144-abcb-1d2ee930ba19",
   "metadata": {},
   "source": [
    "Similar to one-vs-rest, but it **compares each class versus every other class**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae52cefb-48cc-461d-9f96-4bfc2e775d47",
   "metadata": {},
   "source": [
    "<img src=\"img/one-vs-one.png\" width=\"1000\">\n",
    "\n",
    "Using this classification approach, we split the primary dataset into one dataset for each class opposite to every other class. Meaning, more number of datasets and models than OvR. \n",
    "\n",
    "In this example, would be the same, but for more classes, the number grows quickly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b005d176-21d5-49fe-a73e-efc7eda3fab3",
   "metadata": {},
   "source": [
    "üö®**Open Question**\n",
    "\n",
    "Imagine we have a multi-class problem with 5 classes. \n",
    "\n",
    "- How many binary models would OvR build?\n",
    "- How many binary models would OvO build?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a13f596-6ffa-48a1-83ca-3d437e363aa0",
   "metadata": {},
   "source": [
    "## Data analysis workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b82598-935a-4bfe-b495-2a92e0850025",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"img/data_lifecycle.png\" width=\"1200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3acd07d-bb7b-4f31-a938-0bd321072813",
   "metadata": {},
   "source": [
    "### Data Understanding & Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb39a93b-e2f0-448d-84ed-3fd8a5070980",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d199c79f-9cca-4608-a2ec-b7a40fc4e2f3",
   "metadata": {},
   "source": [
    "We start by loading the libraries we will need. \n",
    "\n",
    "‚ö†Ô∏è**Reminder**: during the class, we usually load them as we need them. But we should always load them in the beginning of our code, and only have the ones we actually use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcfbf3d-c013-41ae-92f3-6db9a265469c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f0d36ea-90bd-4e19-a72b-57ee5cf82283",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5808499a-a417-4b50-9f5b-7f6e4782a50e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b39ca2a3-b7a2-4fc4-a790-a1d4b087a46f",
   "metadata": {},
   "source": [
    "#### Data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb76a9-7a39-4663-8479-9989927bd18d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c14db566-26de-4f30-a83e-ceb54d42734b",
   "metadata": {},
   "source": [
    "üö®**Open Question**\n",
    "\n",
    "By looking at the pairplot, What class do you think would be easier to identify?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7d08c-7bd8-4aa7-8f01-d074e5de684f",
   "metadata": {},
   "source": [
    "üö®**Open Question**\n",
    "\n",
    "By looking at the correlation heatmap, What predictors do you think would help most to identify the type of flower?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad321a1c-2883-460f-abb2-a94ca63d6d1a",
   "metadata": {},
   "source": [
    "#### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41772e78-66b1-4445-ab41-96fb246aeea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8845676-c18c-4ad6-9cbb-fa4aae3a4734",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a43c70c-5e82-4936-8a7a-265fbfcb2691",
   "metadata": {},
   "source": [
    "#### Create train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac84488-29f4-4311-b4ae-f7a230352859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31ca2771-6856-4f0a-a4fb-49a974c51022",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90378c-0fa5-4101-9268-9c665993a481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ea1be2e-df0d-4b9f-b056-176b627659cf",
   "metadata": {},
   "source": [
    "üö®**Open Question**\n",
    "\n",
    "If we were to do OHE, and I was planning to use my model in production, why shouldn't I use pandas get_dummies function? \n",
    "\n",
    "What should I use instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a802606b-338c-4218-9812-391d38f3f25f",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee43582-e94e-4616-868b-1ff8ba2912fb",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d0208e-f005-4169-9fa7-6bf1c9341a8d",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è Reminder. Logistic regression is one of the most popular and widely used algorithms for classification problems. As it is also relatively uncomplicated and easy to implement, it is often used as a starting (or naive) model, although it can also produce very high performance results used in production. \n",
    "\n",
    "As we mentioned, **natively only supports binary classification**, which is easy to understand due to the nature of the curve obtained from the logistic equation. However, there are options to **‚Äúadapt‚Äù this model to multi-class problems** (such as we mentioned above). So lets explain it for binary classification.\n",
    "\n",
    "\n",
    "Logistic regression is actually a transformed linear regression function. We can see in the image below that if we tried to fit a linear regression to some data with a binary outcome, we would fit a line that does not predict very well for any values that are not at the extreme values: in the middle there is a lot of area where the line is far away from the points. To bring our function closer to the data, we have to transform the function we are using. In this case, it is useful to use a sigmoid function, which estimates an \"S\" shape. Now we can see that our line fits the data much better. This is what logistic regression does, using the sigmoid function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6be80c-37c5-4ad1-be68-e20132f44fd2",
   "metadata": {},
   "source": [
    "![image.png](img/linear_vs_logistic_regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976af337-aca4-492c-b012-ad8d06afbebc",
   "metadata": {},
   "source": [
    "For multi-class logistic regression we have these options (which goes in **multi_class parameter**):\n",
    "\n",
    "- **OVR**: already explained above. A binary problem is fit for each label.\n",
    "- **Multinomial**: uses softmax function to predict if a single data point falls in one of the N  classes, instead of logistic/sigmoid function.\n",
    "- **Auto**: selects ‚Äòovr‚Äô if the data is binary, or if solver=‚Äôliblinear‚Äô, and otherwise selects ‚Äòmultinomial‚Äô."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7cb032-a360-446c-a037-c66a8ee7cdd5",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è**Remember**: The **C value** in Logistic Regression is an user adjustable parameter that controls **regularisation**. In simple terms, higher values of C will instruct our model to fit the training set as best as possible, while lower C values will favour a simple models with coefficients closer to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc2a14d-ec47-43ca-846b-9ed0efea69eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf47b8e7-597f-4892-a008-a3833c86e26a",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8768326-58b1-496d-8264-ca4aa4366043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb63d102-23f4-42b7-b4b3-b10108cb3a52",
   "metadata": {},
   "source": [
    "#### Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a585ddc-df70-498f-9d77-ae23a7e2b4af",
   "metadata": {},
   "source": [
    "‚ö†Ô∏èAs we explained in other lessons for binary logistic regression, the algorithm's prediction is actually a probability. This probability is transformed into a class prediction according to a threshold. If threshold = 0.5 (default value), then the asigned class is the most probable class (>=0.5). We can move this threshold according to which error (FP, FN) we want to penalize more, i.e. which metric we want to optimize, regarding our business objective. \n",
    "\n",
    "![image.png](img/logistic_prob.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043cce82-125e-4a0a-a919-4b0a0f5c0d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb44fff9-768d-421b-9e6d-d4d78b1987aa",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bfd17a-8343-4f65-9d7b-5cc452d7d212",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "- Confusion matrix helps to visualize the performance of the model\n",
    "- The diagonal elements represent the number of points for which the predicted label is equal to the true label\n",
    "- Off-diagonal elements are those that are mislabeled by the classifier.\n",
    "- The higher the diagonal values of the confusion matrix the better, indicating many correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a8e0fe-0da4-4098-8fbe-cdc765dd4909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "924be9e9-a59d-4c40-98cf-a1eb70816337",
   "metadata": {},
   "source": [
    "#### Classification Report\n",
    "Classification report is used to measure the quality of predictions from a classification algorithm,\n",
    "\n",
    "\n",
    "Quick review:\n",
    "- Precision: Indicates how many classes are correctly classified\n",
    "- Recall: Indicates what proportions of actual positives was identified correctly\n",
    "- F-Score: It is the harmonic mean between precision & recall\n",
    "- Support: It is the number of occurrence of the given class in our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881e63f-b74a-4607-8026-28bae317e285",
   "metadata": {},
   "source": [
    "There are 3 **averaging techniques applicable to multiclass classification**:\n",
    "\n",
    "- **macro**: this is a simple arithmetic mean of all metrics across classes. This technique gives equal weights to all classes making it a **good option for balanced classification tasks.**\n",
    "- **weighted**: **accounts for class imbalance** by computing the average of binary metrics weighted by the number of samples of each class in the target. If 3 (precision scores) for 3 classes are: Class 1 (0.85), class 2 (0.80), and class 3 (0.89), the weighted average will be calculated by multiplying each score by the number of occurrences of each class and dividing by the total number of samples.\n",
    "- **micro**: this is the same as **accuracy**. Micro-averaging is found by dividing the sum of the diagonal cells of the matrix by the sum of all the cells ‚Äî i.e., accuracy. As accuracy is such a **misleading metric**, this averaging technique is rarely used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597bf674-7569-48da-b0a0-2d72afc3d92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1b5431a-a93c-49d6-b4f2-e03a9a7fe702",
   "metadata": {},
   "source": [
    "You must understand the business goal in order to choose the appropiate metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ccdee2-746e-4a57-bd8c-e8217cded069",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Things we have to do while analyzing:\n",
    "1. Load the data\n",
    "2. Explore the data\n",
    "3. Clean the data\n",
    "4. Explore the data again\n",
    "5. Divide the data into train and test\n",
    "6. Do feature engineering: feature encoding (scaling, transforming categorical variables), feature selection... (fit with train, transform with both)\n",
    "7. Train the model with the train dataset. GridsearchCV?\n",
    "8. Make prediction with X_test and with X_train.\n",
    "9. Get metrics comparing y_pred with y_test, same for train (overfitting? underfitting?).\n",
    "10. End. Unless unsatisfactory results, then repeat from any point needed.\n",
    "11. OPT: make a pipeline with step nr. 6 and 7\n",
    "\n",
    "‚ö†Ô∏èReminder:\n",
    "- Classification qualitative variables\n",
    "- Regression are quantitative variables\n",
    "- Multi-class classification:\n",
    "    - Adapt the algorithm? Convert to binary?\n",
    "    - Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c90dfdd-d09a-4640-9e22-a97550322eb2",
   "metadata": {},
   "source": [
    "## Additional resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71831cd5-4b2f-41d8-8da3-ce7f0e6c7caf",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "If you would like to study these concepts for some remedial studying, you can use the resources below:\n",
    "\n",
    "- [ML ‚Äî Multiclass Classification with Imbalanced Dataset](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)\n",
    "- [Video - ML Tutorial: Logistic Regression (Binary Classification)](https://www.youtube.com/watch?v=zM4VZR0px8E)\n",
    "- [Video - ML Tutorial: Logistic Regression (Multiclass Classification)](https://www.youtube.com/watch?v=J5bXOOmkopc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d781c0-d672-467e-ade4-7c21b5a91b59",
   "metadata": {},
   "source": [
    "Refs:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html     \n",
    "https://techdifferences.com/difference-between-linear-and-logistic-regression.html    \n",
    "https://stackoverflow.com/questions/12146914/what-is-the-difference-between-linear-regression-and-logistic-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d427a-6b4f-4699-ab17-07c7165efd41",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4577ffba-740f-422c-8673-341304b697bf",
   "metadata": {},
   "source": [
    "What happens if we use multiclass = multinomial? Compare results with \"ovr\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be010eb0-a6b4-4aaf-b3a0-c0f84034a7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e1b7f-2199-4d23-981c-a74272feac99",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "How would we implement the same code without pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de73b3c3-d3ff-4250-8018-3d9cfd06182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff382a-9728-46d0-b48e-6b31b4b65ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO. Leave the answer only for the teacher side content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b9853d-052c-4e77-8d59-684ebd3fdf40",
   "metadata": {},
   "source": [
    "## Exercise 3 \n",
    "\n",
    "Use KNN for multi-class classification for the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f2edd-34c6-439e-9191-4f793fc7b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ef850-fe2b-4e24-9371-4cf94484e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO. Leave the answer only for the teacher side content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821f3a4f-51c0-4dfc-999d-e10e2d7425d4",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34ff0fe-373f-480c-8fc6-5eef76ea1c33",
   "metadata": {},
   "source": [
    "**ROC Curve**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fbf498-2ad4-496d-a0a3-6be92f6310dd",
   "metadata": {},
   "source": [
    "‚ö†Ô∏èRemember: another commonly used metric in binary classification is AUC (Area Under the Receiver Operating Characteristic Curve). It quantifies the model‚Äôs ability to distinguish between each class. The metric is only used with classifiers that can generate class membership probabilities (in Sklearn, estimators that have a predict_proba() method)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516b6007-108f-4c41-80bd-246fb5937e22",
   "metadata": {},
   "source": [
    "Research how to get the ROC curve for multi-class classification.\n",
    "\n",
    "- Explain how to do it in multi-class and the difference with binary classification ROC curve\n",
    "- Use the library yellowbrick, or your own code, to do a graphical representation of the ROC curves for the iris classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb42b66b-7232-4e96-acd8-07046b7751cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
